{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Unsupervised learning and EDA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Content here is licensed under a CC 4.0 License. The code in this notebook is released under the MIT license. \n",
    "\n",
    "By Manu Flores. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-03T06:46:06.716821Z",
     "start_time": "2019-12-03T06:46:06.710608Z"
    }
   },
   "outputs": [],
   "source": [
    "# uncomment the next line if you're in Google Collab \n",
    "#! pip install -r https://raw.githubusercontent.com/manuflores/grnlearn_tutorial/master/requirements.txt\n",
    "#! wget https://raw.githubusercontent.com/manuflores/grnlearn_tutorial/master/notebooks/grn.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-03T06:46:20.917176Z",
     "start_time": "2019-12-03T06:46:06.726200Z"
    }
   },
   "outputs": [],
   "source": [
    "import grn as g\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn import mixture\n",
    "from umap import UMAP\n",
    "\n",
    "import hvplot\n",
    "import hvplot.pandas\n",
    "import holoviews as hv\n",
    "from holoviews import dim, opts\n",
    "import bokeh_catplot\n",
    "import bokeh \n",
    "import bokeh.io\n",
    "from bokeh.themes import Theme\n",
    "from bokeh.io import output_file, save, output_notebook\n",
    "\n",
    "output_notebook()\n",
    "hv.extension('bokeh')\n",
    "\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\"\n",
    "\n",
    "g.set_plotting_style()\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'svg'\n",
    "\n",
    "seed = 8\n",
    "np.random.seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-03T06:46:20.932799Z",
     "start_time": "2019-12-03T06:46:20.924755Z"
    }
   },
   "outputs": [],
   "source": [
    "theme = Theme(json=g.bokeh_style())\n",
    "bokeh.io.curdoc().theme = theme\n",
    "hv.renderer('bokeh').theme = theme"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hey, cool that you stuck around for the whole tutorial. If you're just arriving to the repo let me just summarize what we've done so far: we extracted a simple genetic network (the Purine metabolism network of *E. coli*), and we used data to learn its patterns, isn't that amazing ! We used a simple linear model to derive the accurately learn the probability that a given gene is inside (our not) regulated or coexpressed in/with this biological module. \n",
    "\n",
    "However, we didn't really performed exploratory data analysis on the dataset, and you've might've felt that it would be cool to have done so. Well, I actually would've wanted this notebook to be the second one, but in the end, the last one was the core of the tutorial so that's why I ended up decided putting it first. But now's the time. Remember when I said that a non-linear dimension reduction would be better for our dataset, well let's continue with that train of thought here. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Unsupervised learning : manifold learning and clustering. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Biological systems are highly non-linear. Even a simple kinetic reaction already involves a non-linear term - and there are thousands of such reactions even in the simplest forms of life (sorry bacteria, I *know* you're not simple) like bacteria. In this sense a linear model like PCA would most of the times, fail to capture the inherent structure of a high-dimensional dataset like the RNAseq data we just analyzed. Moreover, many times, as data scientists we want *to just a feel for the data* by visualizing it. This is were non-linear dimension reduction methods for biology shine!\n",
    "\n",
    "One of the most widely used of such methods is t-SNE. And yeah, there are a lot of biologists that are quite against the t-SNE plots and how they are making (computational) biologists dumb because we are not really seeking for the understanding of the biological system, but here I want to argue that while the latter is true, this techniques help us quite a lot if used correctly. For now I will leave the matter aside and just go ahead and used my favorite non-linear dim reduction method now: UMAP. If you want to get at the gory details of how this method works, I highly recommend this great blog post from [Niko Oskolkov](https://towardsdatascience.com/how-to-program-umap-from-scratch-e6eff67f55fe).\n",
    "\n",
    "\n",
    "Moreover, another approach that we could've have taken to learn the structure of gene networks is an unsupervised one: don't impose any knowledge from the data, let the data speak for itself. In this sense this is a much more exploratory intensive road and one must be careful to investigate that the extracted structure has biological relevance but I also want to argue that this is actually a very very interesting approach (and the most commonly used) for biology. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load in the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Enough of the rant, let's proceed to load in our PCA-denoised data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-03T06:46:20.944876Z",
     "start_time": "2019-12-03T06:46:20.940021Z"
    }
   },
   "outputs": [],
   "source": [
    "path = '../data/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-03T06:46:21.355777Z",
     "start_time": "2019-12-03T06:46:20.952245Z"
    }
   },
   "outputs": [],
   "source": [
    "regulons_with_noise = pd.read_csv(path + 'denoised_coli_palsson_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-03T06:46:21.458466Z",
     "start_time": "2019-12-03T06:46:21.376165Z"
    }
   },
   "outputs": [],
   "source": [
    "regulons_with_noise.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's extract the numerical values only."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-03T06:46:21.484346Z",
     "start_time": "2019-12-03T06:46:21.471656Z"
    }
   },
   "outputs": [],
   "source": [
    "data = regulons_with_noise.iloc[:, 3:].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now proceed to apply the UMAP method. Fortunately, there is a great implementation of UMAP in the [umap-learn](https://umap-learn.readthedocs.io/) library. It also has great documentation, tons of intuitive examples and just an awesome API. It also runs on [Numba](http://numba.pydata.org/), so it is super well optimized. This will take a bit of time, so just remember- patience."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-03T06:46:37.528580Z",
     "start_time": "2019-12-03T06:46:21.498972Z"
    }
   },
   "outputs": [],
   "source": [
    "latent_space = UMAP(n_neighbors = 5, random_state = seed).fit_transform(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-03T06:46:37.552099Z",
     "start_time": "2019-12-03T06:46:37.537434Z"
    }
   },
   "outputs": [],
   "source": [
    "latent_space.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nice. We can see that as a default the UMAP returns a two dimensional latent space of the data but importantly this can scale to $k$-dimensions. Let's proceed to add this UMAP latent space into our data and visualize it with `hvplot`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-03T06:46:37.572479Z",
     "start_time": "2019-12-03T06:46:37.562246Z"
    }
   },
   "outputs": [],
   "source": [
    "regulons_with_noise['UMAP 1'], regulons_with_noise['UMAP 2'] = latent_space[:, 0], latent_space[:, 1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploratory data analysis on the UMAP space"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can finally check if there is a structure to our dataset in the UMAP latent space. First, we'll define some plotting options and then we'll make a scatter plot in the UMAP 2D space. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-03T06:46:37.636571Z",
     "start_time": "2019-12-03T06:46:37.581513Z"
    }
   },
   "outputs": [],
   "source": [
    "regulons_with_noise.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-03T06:46:37.661691Z",
     "start_time": "2019-12-03T06:46:37.644962Z"
    }
   },
   "outputs": [],
   "source": [
    "dots_kws = {'padding': 0.2,\n",
    "            'alpha' : 0.3,\n",
    "            'tools': ['hover'],\n",
    "            'color' : 'orange',\n",
    "            'show_grid': True, \n",
    "            'width': 420, \n",
    "            'height': 300,\n",
    "            'size': 5}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-03T06:46:37.866217Z",
     "start_time": "2019-12-03T06:46:37.674223Z"
    }
   },
   "outputs": [],
   "source": [
    "dots= hv.Points(data = regulons_with_noise,\n",
    "           kdims = ['UMAP 1', 'UMAP 2'],\n",
    "           vdims = ['gene_name']).opts(**dots_kws,\n",
    "                                       \n",
    "                                      xlabel= 'UMAP 1',\n",
    "                                      ylabel = 'UMAP 2' )\n",
    "\n",
    "dots"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-03T05:20:05.204705Z",
     "start_time": "2019-12-03T05:20:04.541888Z"
    }
   },
   "source": [
    "Interesting ! We can see that there is like a manifold that our data lies in. Now, let's try to find out what is the hidden variables in the manifold. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-31T21:28:14.095666Z",
     "start_time": "2019-10-31T21:28:13.925718Z"
    }
   },
   "source": [
    "### Clustering and extracting data. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Because of the structure of the latenst space, a good algorithm to try would be one that is based on density (e.g. DBSCAN) or that can extract nonlinear features to cluster. \n",
    "\n",
    "A perhaps even simpler approach is to just try to approximate the dataset using a mixture of 2D Gaussian distributions, i.e. a Gaussian mixture model. This algorithm is strikingly fast because it uses variational inference and converges almost instantly. \n",
    "\n",
    "One thing to do before is to choose how many clusters we want to extract from the data, i.e. how many Gaussians does the dataset actually encode. We can use the relevant biological information from the analysisi in the first notebook: the TRN can be partitioned into 16 clusters. Let's use this for for our number of components. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-03T06:46:39.549200Z",
     "start_time": "2019-12-03T06:46:37.875241Z"
    }
   },
   "outputs": [],
   "source": [
    "# Fit a Dirichlet process Gaussian mixture \n",
    "dpgmm = mixture.BayesianGaussianMixture(n_components=16,\n",
    "                                        covariance_type='full', \n",
    "                                        random_state = seed).fit(latent_space)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Because the GMM is a probabilistic generative model, we can calculate the probabililty that each gene is a member of each cluster. This let's us assign multiple clusters to a given gene if we wanted to."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-03T06:46:39.606076Z",
     "start_time": "2019-12-03T06:46:39.560620Z"
    }
   },
   "outputs": [],
   "source": [
    "probs = dpgmm.predict_proba(latent_space)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look at the output to see what's the probability of the first 5 genes to be in the first four clusters. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-03T06:46:39.632323Z",
     "start_time": "2019-12-03T06:46:39.623374Z"
    }
   },
   "outputs": [],
   "source": [
    "probs[:5, :4]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's use the `predict`method to get the most likely clusters each gene belongs to."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-03T06:46:39.661730Z",
     "start_time": "2019-12-03T06:46:39.645527Z"
    }
   },
   "outputs": [],
   "source": [
    "labels = dpgmm.predict(latent_space)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also check how many genes are in each cluster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-03T06:46:39.701633Z",
     "start_time": "2019-12-03T06:46:39.678306Z"
    }
   },
   "outputs": [],
   "source": [
    "pd.Series(labels).value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's add the labels to visualize our clusters in the latent space. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-03T06:46:39.722945Z",
     "start_time": "2019-12-03T06:46:39.712687Z"
    }
   },
   "outputs": [],
   "source": [
    "regulons_with_noise['cluster_labels'] = labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-03T06:46:39.989980Z",
     "start_time": "2019-12-03T06:46:39.733848Z"
    }
   },
   "outputs": [],
   "source": [
    "regulons_with_noise.hvplot(kind = 'scatter',\n",
    "                           x = 'UMAP 1',\n",
    "                           y = 'UMAP 2',\n",
    "                           c = 'cluster_labels',\n",
    "                           hover_cols = ['gene name'],\n",
    "                           s = 80, alpha = 0.1).opts(cmap = 'magma',\n",
    "                                                      padding = 0.5,\n",
    "                                                      height = 350, \n",
    "                                                      width = 500,\n",
    "                                                      colorbar_opts={'title':'clusters'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nice! From exploring the data we can see that cluster 4 and cluster 10 are the furthest appart in the manifold. Let's check if there's an enriched function for each of this datasets. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-03T06:46:40.023088Z",
     "start_time": "2019-12-03T06:46:40.006193Z"
    }
   },
   "outputs": [],
   "source": [
    "# extract the data from cluster 11 and 6\n",
    "c6 = regulons_with_noise[regulons_with_noise['cluster_labels'] == 6]\n",
    "c11 = regulons_with_noise[regulons_with_noise['cluster_labels'] == 11]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-03T06:46:40.131966Z",
     "start_time": "2019-12-03T06:46:40.062655Z"
    }
   },
   "outputs": [],
   "source": [
    "c6.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-03T06:46:40.152485Z",
     "start_time": "2019-12-03T06:46:40.145093Z"
    }
   },
   "outputs": [],
   "source": [
    "# extract the genes from cluster 4 and 10 a\n",
    "c6_genes = c6['gene_name'].values\n",
    "c11_genes = c11['gene_name'].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Enriched biological functions. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A normal approach to find the enriched or overrepresented functions in a set of genes, in our case, the clusters in the UMAP space, is to make a statistical test. The story is that we can approximate genome as a *bag of gene names*, therefore the probability to get a drawing a number of genes from a given biological module (say of the fatty acid metabolic pathway) from this bag is hypergeometrically distributed. Don't worry if you don't get the gist of the statistical story, but essentially we are going to test if a given biological function is enriched in our clusters. \n",
    "\n",
    "To get the annotations I got the *E. coli* annotation data from [Gene Ontology]('http://geneontology.org/') which is kind of a gold standard of biological function annotations. The full annotation can be found [here](https://zenodo.org/record/3552960).\n",
    "\n",
    "I also made a wrapper function to call make the test on python. It's still work in progress but it will be good for now. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-03T06:46:41.093480Z",
     "start_time": "2019-12-03T06:46:40.165552Z"
    }
   },
   "outputs": [],
   "source": [
    "# Run the enrichment test on the genes of cluster 6\n",
    "go_test_c6 = g.get_GO_enrichment(c6_genes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-03T06:46:41.149710Z",
     "start_time": "2019-12-03T06:46:41.107069Z"
    }
   },
   "outputs": [],
   "source": [
    "go_test_c6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Interesting ! We can see that the functions enriched appear to be metal binding enzymes. Don't pay too much attention to the p-values, I still have to work on correcting them. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-03T06:46:42.534594Z",
     "start_time": "2019-12-03T06:46:41.167138Z"
    }
   },
   "outputs": [],
   "source": [
    "# Same for cluster 11\n",
    "go_test_c11 = g.get_GO_enrichment(c11_genes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It looks like there are no statistically enriched functions for cluster 11. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hmm. It seems that we didn't got too much information to go on to the tips of the latent space. Let's see if we have any luck by going into the center of it. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-03T06:46:43.367383Z",
     "start_time": "2019-12-03T06:46:42.541984Z"
    }
   },
   "outputs": [],
   "source": [
    "c0 = regulons_with_noise[regulons_with_noise['cluster_labels'] == 0]\n",
    "c0_genes = c0['gene_name'].values\n",
    "go_test_c0 = g.get_GO_enrichment(c0_genes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-03T06:46:43.398196Z",
     "start_time": "2019-12-03T06:46:43.378065Z"
    }
   },
   "outputs": [],
   "source": [
    "go_test_c0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Interesting, it looks like we got a bunch of endonucleases and DNA repairing enzymes. \n",
    "\n",
    "Don't think that I'm a biological / *E. coli* genie, I just looked for information at [Ecocyc](https://ecocyc.org/). In this sense, I can be pretty sure that the clusters derived from the UMAP latent space are yielding biologically meaningful relationships. Exploring this dataset could take quite some time (it was two full years of my undergrad thesis), so I'll stop here and let you continue with the analysis if you're interested. \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Another idea for post- clustering analysis\n",
    "\n",
    "Another interesting idea would be to see if there are related transcription factors in each cluster. You now have the tools to answer this question!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Last words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This was a fun ride in biological data analysis! I just want to acknowledge that most of this tutorial was based on work I did in the Pérez-Rueda Lab. \n",
    "\n",
    "Let me know if you have any questions and feel free to reach out if you want to collaborate in extending these ideas! \n",
    "\n",
    "**GRN** = **G**ene **R**egulatory **N**etwork\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
