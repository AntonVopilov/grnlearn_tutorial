{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analyzing the transcriptional regulatory network of *E. coli*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Content here is licensed under a CC 4.0 License. The code in this notebook is released under the MIT license. \n",
    "\n",
    "\n",
    "By Manu Flores. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-03T05:53:50.765595Z",
     "start_time": "2019-12-03T05:53:50.760724Z"
    }
   },
   "outputs": [],
   "source": [
    "# uncomment the next line if you're in Google Collab \n",
    "#! pip install -r https://raw.githubusercontent.com/manuflores/grnlearn_tutorial/master/requirements.txt\n",
    "#! wget https://raw.githubusercontent.com/manuflores/grnlearn_tutorial/master/notebooks/grn.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-03T05:54:09.397144Z",
     "start_time": "2019-12-03T05:53:50.773407Z"
    }
   },
   "outputs": [],
   "source": [
    "import grn as g\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import networkx as nx\n",
    "import matplotlib as mpl\n",
    " \n",
    "import hvplot\n",
    "import hvplot.pandas\n",
    "import holoviews as hv\n",
    "from holoviews import dim, opts\n",
    "import bokeh_catplot\n",
    "import bokeh \n",
    "import bokeh.io\n",
    "from bokeh.io import output_file, save, output_notebook\n",
    "output_notebook()\n",
    "hv.extension('bokeh')\n",
    "\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\"\n",
    "\n",
    "g.set_plotting_style()\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'svg'\n",
    "\n",
    "seed = 8 \n",
    "np.random.seed(seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load transcriptional regulatory network (TRN)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First - off in this exploration, let's load the transcriptional regulatory network of E. coli. We'll use pandas to load the data into the notebook and then use NetworkX to analyze it. \n",
    "\n",
    "This network was downloaded from [RegulonDB](http://regulondb.ccg.unam.mx/menu/download/datasets/). RegulonDB is the largest knowledge-base / database of *E. coli* and is mantained by the group of [Julio Collado](http://www.ccg.unam.mx/pedro-julio-collado-vides/) at UNAM, and there are similar databases for other model organisms such as [SubtiWiki](http://subtiwiki.uni-goettingen.de/) for *B. subtilis* (curated by the group of Jörg Stülke at University of Göttingen) and [WormBase](https://www.wormbase.org/) from the [Paul Sternberg](http://wormlab.caltech.edu/) lab at Caltech. This databases are great resources to start studying about model organisms through biological data analysis. \n",
    "\n",
    "If you're running the notebook in Google Colab you will have to download it using the `wget` command from unix before hand. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-03T05:54:09.411838Z",
     "start_time": "2019-12-03T05:54:09.404076Z"
    }
   },
   "outputs": [],
   "source": [
    "# uncomment the following line if you're in Google colab\n",
    "# url = 'https://raw.githubusercontent.com/manuflores/grnlearn_tutorial/master/data/trn_ecoli.txt'\n",
    "# df_trn = pd.read_csv(url,  comment= '#',\n",
    "#                     delimiter = '\\t', index_col = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-03T05:54:09.446609Z",
     "start_time": "2019-12-03T05:54:09.415745Z"
    }
   },
   "outputs": [],
   "source": [
    "# Read in the transcriptional regulatory network file \n",
    "df_trn = pd.read_csv('../data/trn_ecoli.txt',  comment= '#',\n",
    "                     delimiter = '\\t', index_col = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look at the dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-03T05:54:09.526860Z",
     "start_time": "2019-12-03T05:54:09.450033Z"
    }
   },
   "outputs": [],
   "source": [
    "df_trn.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The way the dataset is arranged is that each row is an interaction, the `tf` correspond to the **transcription factors**, and the `tg` column to the **target gene** that's being regulated by the TF.\n",
    "\n",
    "We can now turn it into a graph object using NetworkX. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-03T05:54:09.573474Z",
     "start_time": "2019-12-03T05:54:09.530455Z"
    }
   },
   "outputs": [],
   "source": [
    "# Pandas DataFrame to a NetworkX graph object\n",
    "trn = nx.from_pandas_edgelist(df= df_trn,\n",
    "                              source= 'tf',\n",
    "                              target='tg')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In reality, this network is a directed graph, but for simplicity let's treat it as an undirected network. \n",
    "\n",
    "We can now go ahead and get the global regulators of the TRN, a.k.a. the hubs. There are several [centrality measures](https://networkx.github.io/documentation/stable/reference/algorithms/centrality.html) in NetworkX, we'll use the eigenvector centrality. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-03T05:54:10.603295Z",
     "start_time": "2019-12-03T05:54:09.577774Z"
    }
   },
   "outputs": [],
   "source": [
    "# Calculating eigenvector centrality to get the hubs\n",
    "eigen_cen= nx.eigenvector_centrality(trn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The output of the function is a dictionary of tuples corresponding to the gene name of each node in the network and its eigenvector centrality. Let's make a list out of it and print the first 10 elements. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-03T05:54:10.625479Z",
     "start_time": "2019-12-03T05:54:10.608450Z"
    }
   },
   "outputs": [],
   "source": [
    "list(eigen_cen.items())[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that these are arranged in alphabetical order. We can arrange them by its centrality and then return the first 10 most central nodes, i.e. the hubs. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-03T05:54:10.652157Z",
     "start_time": "2019-12-03T05:54:10.632661Z"
    }
   },
   "outputs": [],
   "source": [
    "# sort the dictionary to get the hubs\n",
    "hubs= sorted(eigen_cen.items(), key= lambda cc: cc[1], reverse= True)[:10]\n",
    "\n",
    "hubs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nice! We actually get the most important global transcription factors in the network. We can corroborate by just getting the top 10 TFs with the most interactions from the dataframe. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-03T05:54:10.682302Z",
     "start_time": "2019-12-03T05:54:10.660849Z"
    }
   },
   "outputs": [],
   "source": [
    "# Get the first \n",
    "df_trn.tf.value_counts().head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualizing the transcription regulatory network. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's proceed with our analysis by plotting the network itself. Specifically, we want to tease out the structure of the net by looking at it. \n",
    "\n",
    "Before we go and plot the whole network, let's extract its [largest connected component](https://en.wikipedia.org/wiki/Component_(graph_theory)). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-03T05:54:10.872397Z",
     "start_time": "2019-12-03T05:54:10.686766Z"
    }
   },
   "outputs": [],
   "source": [
    "# Extract the network's larget_connected_component\n",
    "trn_lcc = max(nx.connected_component_subgraphs(trn), key=len)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The NetworkX library has an off-the-shelf function to plot networks using a Matplotlib backend, it also has different layouts to explore. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-03T05:54:48.678244Z",
     "start_time": "2019-12-03T05:54:10.884328Z"
    }
   },
   "outputs": [],
   "source": [
    "nx.draw(trn_lcc,\n",
    "        node_color = 'lightgreen',\n",
    "        node_label = False,\n",
    "        alpha = 0.6,\n",
    "        node_size = 30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nice! From the network we can (kind of) tease out that this fuzzball might have some nice structure to it : inside it is a very convoluted hairball, but in the edges we see some clear structure: **few nodes regulate many nodes**. Moreover the net **organizes into clusters**, we'll get back to that in the next tutorial. This is typical of real world networks, like social networks, power grids, and really most biological networks. This type of nets are generally known as **scale-free networks**. \n",
    "\n",
    "We can more easily this pattern if we plot the distributions number of connections of each node in the network, i.e. the degree distribution. Let's extract that information, put it inside at a dataframe and plot it using the `bokeh_captlot` package from the great Justin Bois.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-03T05:54:49.310318Z",
     "start_time": "2019-12-03T05:54:48.683012Z"
    }
   },
   "outputs": [],
   "source": [
    "# Get all the gene names for the nodes in the net\n",
    "nodes = [node for node in trn.nodes()]\n",
    "\n",
    "# Get the degree of each node\n",
    "degree_distro = [degree for  node, degree in trn.degree()]\n",
    "\n",
    "# Make a list corresponding to the annotation in the network\n",
    "tf_annot = [ 'tf' if node in df_trn.tf.values else 'tg' for node in nodes ]\n",
    "\n",
    "# Save this information in a tidy dataframe\n",
    "net_stats = pd.DataFrame(\n",
    "    {'gene_name': nodes,\n",
    "     'degree_distribution': degree_distro, \n",
    "     'tf_annot': tf_annot}\n",
    ")\n",
    "\n",
    "net_stats.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nice, we can now go ahead and plot the distribution it using `bokeh_catplot`. This is an awesome library to visualize distributions using interactive plots in bokeh. [The library was made by Justin Bois](https://github.com/justinbois/bokeh-catplot)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-03T05:54:49.553230Z",
     "start_time": "2019-12-03T05:54:49.313601Z"
    }
   },
   "outputs": [],
   "source": [
    "# Plot degree distribution\n",
    "p = bokeh_catplot.strip(\n",
    "    data = net_stats,\n",
    "    val = 'degree_distribution',\n",
    "    cats = 'tf_annot',\n",
    "    jitter = True, \n",
    "    horizontal = True,\n",
    "    tooltips = [('gene_name', '@gene_name'),\n",
    "                ('tf_annot', '@tf_annot')],\n",
    "    marker_kwargs={'alpha': 0.5},\n",
    "    palette= ['#fc8d62', '#8da0cb'], \n",
    ")\n",
    "\n",
    "\n",
    "bokeh.io.show(p)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nice! We can clearly see that a lot of TFs that have more than 10 interactions in the network- We can also see that the most heavily regulated genes have more than 10 incoming TFs too!\n",
    "\n",
    "What if we wanted to zoom in to a certain region of the network? Well, we can do it effectively using high-level commands of the [`hvplot.networkx`](https://hvplot.pyviz.org/user_guide/NetworkX.html) module. Let's also activate the hover tool in order to see the gene name when we put the cursor in a given node. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-03T05:55:20.347656Z",
     "start_time": "2019-12-03T05:54:49.558850Z"
    }
   },
   "outputs": [],
   "source": [
    "import hvplot.networkx as hvnx\n",
    "\n",
    "spring = hvnx.draw(trn_lcc,\n",
    "                   node_color = 'lightgreen',\n",
    "                   node_size = 30,\n",
    "                   alpha = 0.6, \n",
    "                   with_labels=False)\n",
    "\n",
    "spring.opts(tools = ['hover'],height = 600, width = 600)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Despite this is not the best visualization possible with the power of Holoviews, we can now start exploring the network in detail. We can clearly see how the network the ramifications at the edges, and if we zoom to them, we will se some operons like the tryptophan biosynthesis one in the upper left. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clustering the transcriptional regulatory network. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So far we've seen that the TRN has a scale-free structure, and that it organizes into well defined clusters. \n",
    "\n",
    "What if we wanted to actually get the clusters directly from the network data? Well, we can do this with a community detection algorithm. One of the most well established network community algorithms is called the [Louvain algorithm](https://arxiv.org/pdf/0803.0476). The name of the algorithm comes from the fact that the first author work (or worked) at the Louvain [University in Belgium](https://uclouvain.be/fr/index.html). This algorithm is implemented in the [`python-louvain`](https://python-louvain.readthedocs.io/en/latest/api.html) library in python. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-03T05:55:20.355067Z",
     "start_time": "2019-12-03T05:55:20.349858Z"
    }
   },
   "outputs": [],
   "source": [
    "import community"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can call the algorithm directly on the largest connected component to extract the network clusters. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-03T05:55:21.798887Z",
     "start_time": "2019-12-03T05:55:20.360033Z"
    }
   },
   "outputs": [],
   "source": [
    "communities_trn = community.best_partition(trn_lcc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see how many clusters we get. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-03T05:55:21.811767Z",
     "start_time": "2019-12-03T05:55:21.802298Z"
    }
   },
   "outputs": [],
   "source": [
    "#How many clusters do we get with the TRN's LCC? \n",
    "n_clusters = max(communities_trn.values())\n",
    "n_clusters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now proceed to set the cluster valuyes as network attributes in the `nx.Graph`object. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-03T05:55:21.826188Z",
     "start_time": "2019-12-03T05:55:21.816637Z"
    }
   },
   "outputs": [],
   "source": [
    "nx.set_node_attributes(trn_lcc,\n",
    "                       values= communities_trn,\n",
    "                       name = 'modularity')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With this in place, we can now iterate over the nodes object in the network to get the cluster for each node in the network. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-03T05:55:21.839054Z",
     "start_time": "2019-12-03T05:55:21.829873Z"
    }
   },
   "outputs": [],
   "source": [
    "cluster_list = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-03T05:55:21.880769Z",
     "start_time": "2019-12-03T05:55:21.842286Z"
    }
   },
   "outputs": [],
   "source": [
    "for i in range(n_clusters):\n",
    "\n",
    "    cluster_lcc = [n for n in trn_lcc.nodes()\\\n",
    "                   if trn_lcc.node[n]['modularity'] == i]\n",
    "\n",
    "    cluster_list.append(cluster_lcc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look at the first 10 members of cluster 3. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-03T05:55:21.894972Z",
     "start_time": "2019-12-03T05:55:21.883759Z"
    }
   },
   "outputs": [],
   "source": [
    "cluster_list[2][:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nice! If we wanted to get a more high-level view of the core clusters of the regulatory net, it would be better to do the clustering in the TF-TF network, that is, only consider the interactions corresponding to transcription factors. You can download the TF-TF network from [RegulonDB](http://regulondb.ccg.unam.mx/menu/download/datasets/) in the TF-TF interactions section. I'll leave this as an exercise for people that want to go forward with this analysis. You can then interpret your clusters using information from [Ecocyc](http://ecocyc.org/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-03T05:55:21.907407Z",
     "start_time": "2019-12-03T05:55:21.900266Z"
    }
   },
   "outputs": [],
   "source": [
    "#write your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extracting the PurR regulon from the regulatory network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before we end, let's extract the data the PurR regulon. A regulon is a group of genes co-regulated by a TF or set of TFs. We'll use this annotation we'll use to label our data and train an ML model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-03T05:55:21.933852Z",
     "start_time": "2019-12-03T05:55:21.918397Z"
    }
   },
   "outputs": [],
   "source": [
    "df_trn.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-03T05:55:21.959016Z",
     "start_time": "2019-12-03T05:55:21.949711Z"
    }
   },
   "outputs": [],
   "source": [
    "# Selecting the data corresponding to the PurR regulon\n",
    "pur_regulon = df_trn[df_trn['tf'] == 'purr']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-03T05:55:21.973141Z",
     "start_time": "2019-12-03T05:55:21.962913Z"
    }
   },
   "outputs": [],
   "source": [
    "pur_regulon.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-03T05:55:21.984072Z",
     "start_time": "2019-12-03T05:55:21.976908Z"
    }
   },
   "outputs": [],
   "source": [
    "#pur_regulon.to_csv('../../data/purr_regulon_rdb.csv', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The PurR regulon will serve as our training set. But how can we really make a prediction of the possible targets of the PurR transcription factors ? And furthermore, how can we know if our predictions are right. Well, we'll need another dataset to compare against. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Palsson lab hiTRN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The [Palsson Lab](http://systemsbiology.ucsd.edu/Researchers/Palsson) at UCSD has expanded the TRN of *E. coli* in RegulonDB, using a technique called ChIP-seq. They coined this expanded network of high-confidence interactions, **the hiTRN**. They published a [study](https://www.pnas.org/content/114/38/10286.long) a couple of years ago, where they compiled the knowledge generated of more than a decade of work and made a really neat analysis on the core modules of the network.\n",
    "\n",
    "Let's load the hiTRN and extract the PurR regulon. This will serve as our test dataset for the ML model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-03T05:55:22.000387Z",
     "start_time": "2019-12-03T05:55:21.994822Z"
    }
   },
   "outputs": [],
   "source": [
    "#Run this cell if you're in collab\n",
    "# url_hi_trn = 'https://raw.githubusercontent.com/manuflores/grnlearn_tutorial/master/data/hiTRN_palsson_lab.csv'\n",
    "# hiTRN = pd.read_csv(url_hi_trn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-03T05:55:22.035440Z",
     "start_time": "2019-12-03T05:55:22.006617Z"
    }
   },
   "outputs": [],
   "source": [
    "# Load the hiTRN \n",
    "hiTRN = pd.read_csv('../data/hiTRN_palsson_lab.csv')\n",
    "hiTRN.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-03T05:55:22.051829Z",
     "start_time": "2019-12-03T05:55:22.040867Z"
    }
   },
   "outputs": [],
   "source": [
    "# Extract the PurR regulon of the hiTRN \n",
    "pur_regulon_hi = hiTRN[hiTRN['TF'] == 'PurR']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Because some nodes have more than one interaction, let's just keep the TF and gene columns and drop duplicated interactions. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-03T05:55:22.065056Z",
     "start_time": "2019-12-03T05:55:22.055070Z"
    }
   },
   "outputs": [],
   "source": [
    "purr_hi = pur_regulon_hi[['TF', 'gene']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-03T05:55:22.079340Z",
     "start_time": "2019-12-03T05:55:22.067881Z"
    }
   },
   "outputs": [],
   "source": [
    "purr_hi.drop_duplicates(inplace =True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can finally save our dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-03T05:55:22.091004Z",
     "start_time": "2019-12-03T05:55:22.085676Z"
    }
   },
   "outputs": [],
   "source": [
    "#purr_hi.to_csv('../../data/purr_regulon_hitrn.csv', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "All right, we're good to go ! In this tutorial we have explored a bit of the the genetic network of *E. coli* and gotten a general feel of its structure. In the next tutorial we'll use the regulons extracted in this notebook to train our ML model. \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
